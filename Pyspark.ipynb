{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9aef793d-810b-4750-9688-7988f7671407",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Load CSV to Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4c81f93c-9021-439b-82b5-8b88cb839f91",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Cell 2"
    }
   },
   "outputs": [],
   "source": [
    "df=spark.read.format(\"csv\").option(\"header\",\"true\").option(\"inferSchema\",\"true\").load(\"/Volumes/databricks_simulated_retail_customer_data/v01/source_files\")\n",
    "#df.show()\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "decf41f8-df35-4dff-9fd5-9b31f47bae20",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Load dataframe to CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "23bb0b17-a5f3-4749-a8c5-14bbb63afa35",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df.write.format(\"csv\").mode(\"overwrite\").save(\"/Volumes/test_catalog/schema__t1/volume__t1\")\n",
    "#this will give multiple files in the folder because:\n",
    "#Spark Splits the DataFrame into partitions\n",
    "#Each partition is written by one executor\n",
    "#Each partition → one file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a38d762b-ee29-4d36-b575-7d207803bbb4",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Cell 5"
    }
   },
   "outputs": [],
   "source": [
    "df.coalesce(1).write.format(\"csv\").mode(\"overwrite\").save(\"/Volumes/test_catalog/schema__t1/volume__t1\")\n",
    "#This will give me one file in the folder because:\n",
    "#.coalesce(1) → 1 partition\n",
    "#but not efficient therefore should not be used. \n",
    "\n",
    "#Other saving modes are:\n",
    "#- overwrite\n",
    "#- append\n",
    "#- ignore\n",
    "#- errorIfExists"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f4212509-f29f-47a6-a2e3-590ad13ce318",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "WithColumn\n",
    "Used for:\n",
    "- adding new column\n",
    "- updating a value\n",
    "- change datatype\n",
    "\n",
    "from pyspark.sql.functions import col\n",
    "\n",
    "df = df.withColumn(\"column_name\", expression)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "143401b0-a68c-4d53-a923-47a0cc15ea90",
     "showTitle": true,
     "tableResultSettingsMap": {},
     "title": "Cell 7"
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col \n",
    "df1=df.withColumn(\"customer_id\",col(\"customer_id\").cast(\"int\"))\n",
    "display(df1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3471ba8e-4f1a-4ddd-a2db-9e27e7ec5c7b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "Pyspark",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
